{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\UFMG\\Mestrado periodo\\BI_PREDEP\\Chen\\neural-approx-ss-lfi-main\\problems\\problem_IS.py:16: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  A d*d Ising model                                                           H(x; theta) = alpha* \\sum_<i,j> xi*xj + beta* \\sum_i x_i\n"
     ]
    }
   ],
   "source": [
    "import os, sys, inspect, time\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "import discrepancy, visualization\n",
    "from algorithms import ABC_algorithms, TPABC, SMCABC, SMC2ABC, SNLABC, SNL2ABC\n",
    "from problems import problem_IS\n",
    "\n",
    "import utils_os, utils_math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " sampling from true posterior ... \n",
      "\n",
      "x_obs= [[-1. -1. -1. -1.  1. -1. -1.  1.]\n",
      " [-1.  1. -1. -1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.  1.  1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1. -1.  1.  1.]\n",
      " [ 1.  1.  1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  1.  1. -1. -1. -1. -1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1.  1.]\n",
      " [-1. -1. -1. -1.  1. -1. -1.  1.]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'log_likelihood'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m## Visualize\u001b[39;00m\n\u001b[32m     38\u001b[39m problem.visualize()  \n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m visualization.plot_likelihood(samples=true_samples, log_likelihood_function=\u001b[43mtp_abc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_likelihood\u001b[49m)\n\u001b[32m     40\u001b[39m plt.savefig(\u001b[33m'\u001b[39m\u001b[33mIS_true_posterior.png\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'log_likelihood'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIUAAACFCAYAAAB12js8AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAkpJREFUeJzt3cFq4lAYgNEos1X3Ut//wQrurXszZKAg88GMY1prOudsShcpIfm4hv7cuBrHcRzgyvr6F5iIghAFIQpCFIQoCFEQP4YbXC6X4Xg8DpvNZlitVrccwhOa/iV1Pp+H/X4/rNfreVFMQRwOh488P77Q6+vr8PLyMi+KaYV4/2Pb7Xb4rna73V3HnU6nYSnnen0/Z0Xx/pExBfGdo7jXdmHX5G+PAB40CVEQoiBEQYiCEAUhCkIUhCgIURCi4L7Zxxz3jtq/YufBknY7jHec69vb202DNCsFIQpCFIQoCFEQoiBEQYiCEAUhCkIUhCgIUfD4KemSJo+P3jw9Pum1sVIQoiBEQYiCEAUhCkIUhCgIURCiIERBiIIQBSEKHj86X5JHj7JXT/qecysFIQpCFIQoCFEQoiBEQYiCEAUhCkIUhCgIUTBvSjrnuzAf6Vk37n71eXoNM3cTBSEKQhSEKAhREKIgREGIghAFIQpCFIQoCHtJF2r1iftQrRSEKAhREKIgREGIghAFIQpCFIQoCFEQoiBEwbwp6el0Grbb7b8cwgJZKQhREKIgREGIghAFIQpCFIQoCFEQoiBEQYiCEAVhg/EHbNodF/La51tZKQhREKIgREGIghAFIQpCFIQoCFEQoiBEwX0DsfeBz/S9ltTSrsvfBng3RXE+n3/9PBwOH3NW38xuIV/ie30//3TOq/GGue/lchmOx+Ow2Ww+9Z3QfK7pVk9B7Pf7Yb1ez4uC/4sHTUIUhCgIURCiIERBiILhdz8BD+JoG3JsTHQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DIR = 'results/IS'                                             \n",
    "RERUN = not utils_os.is_file_exist(DIR, 'true_samples.npy') \n",
    "\n",
    "## Define the problem\n",
    "problem = problem_IS.IS_Problem(N=500, n=1)\n",
    "true_theta = problem.get_true_theta()\n",
    "\n",
    "## Get x_o ~ p(x|theta)\n",
    "if RERUN:\n",
    "    # observed data x_o\n",
    "    problem.data_obs = problem.simulator(true_theta)\n",
    "    problem.y_obs = problem.statistics(data=problem.data_obs)\n",
    "    utils_os.save_object(DIR, 'data_obs', problem.data_obs)\n",
    "    utils_os.save_object(DIR, 'y_obs', problem.y_obs)\n",
    "else:\n",
    "    problem.data_obs  = utils_os.load_object(DIR, 'data_obs.npy')\n",
    "    problem.y_obs  = problem.statistics(data=problem.data_obs)\n",
    "    \n",
    "\n",
    "## Get True posterior (rejection sampling approximation with 1D sufficient stat)\n",
    "print('\\n sampling from true posterior ... \\n')\n",
    "hyperparams = ABC_algorithms.Hyperparams()\n",
    "hyperparams.save_dir = DIR\n",
    "hyperparams.num_sim = 40000\n",
    "hyperparams.num_samples = 150\n",
    "hyperparams.device = 'cuda:3'\n",
    "hyperparams.L = 1\n",
    "tp_abc = TPABC.TP_ABC(problem, discrepancy=discrepancy.eculidean_dist, hyperparams=hyperparams)\n",
    "if RERUN:\n",
    "    tp_abc.run()\n",
    "    true_samples = tp_abc.rej_samples\n",
    "    utils_os.save_object(DIR, 'true_samples', true_samples)\n",
    "else:\n",
    "    tp_abc = utils_os.load_algorithm(DIR, tp_abc)\n",
    "    true_samples = utils_os.load_object(DIR, 'true_samples.npy')\n",
    "    \n",
    "## Visualize\n",
    "problem.visualize()  \n",
    "visualization.plot_likelihood(samples=true_samples, log_likelihood_function=tp_abc.log_likelihood)\n",
    "plt.savefig('IS_true_posterior.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMC-ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequential Monte Carlo ABC +\n",
    "\n",
    "hyperparams = ABC_algorithms.Hyperparams()\n",
    "hyperparams.save_dir = DIR\n",
    "hyperparams.device = 'cuda:1'\n",
    "hyperparams.num_sim = 2000                       # number of simulations\n",
    "hyperparams.num_samples = 150                    # number of samples to represent posterior\n",
    "hyperparams.L = 2                                # number of learning rounds\n",
    "hyperparams.type = 'cnn2d'                       # the network architecture of S(x)\n",
    "hyperparams.stat = 'infomax'                     # statistics function: infomax/moment/score  \n",
    "hyperparams.estimator = 'PREDEP'                    # MI estimator; JSD or DC, see the paper\n",
    "\n",
    "smc2_abc = SMC2ABC.SMC2_ABC(problem, discrepancy=discrepancy.eculidean_dist, hyperparams=hyperparams)\n",
    "smc2_abc.run()\n",
    "\n",
    "JSD_smc2_array = []\n",
    "for l in range(len(smc2_abc.posterior_array)):\n",
    "    print('l=', l)\n",
    "    smc2_abc.l = l\n",
    "    smc2_abc.posterior = smc2_abc.posterior_array[l]\n",
    "    visualization.plot_likelihood(samples=true_samples, log_likelihood_function=smc2_abc.log_likelihood, dimensions=(0,1))\n",
    "    JSD = discrepancy.JSD(tp_abc.log_likelihood, smc2_abc.log_likelihood, true_samples, true_samples, N_grid=30)\n",
    "    JSD_smc2_array.append(JSD)\n",
    "    print('JSD smc2 = ', JSD)\n",
    "utils_os.save_object(DIR, 'JSD_SMC2', JSD_smc2_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sequential Neural Likelihood + \n",
    "hyperparams = ABC_algorithms.Hyperparams()\n",
    "hyperparams.save_dir = DIR\n",
    "hyperparams.device = 'cuda'\n",
    "hyperparams.num_sim = 4000                       # number of simulations\n",
    "hyperparams.L = 2                                # number of learning rounds\n",
    "hyperparams.type = 'cnn2d'                       # the network architecture of S(x)\n",
    "hyperparams.stat = 'infomax'                     # statistics function: infomax/moment/score   \n",
    "hyperparams.estimator = 'PREDEP'                    # MI estimator; JSD or DC, see the paper\n",
    "hyperparams.nde = 'MAF'                          # nde; MAF (D>1) or MDN (D=1)\n",
    "\n",
    "snl2_abc = SNL2ABC.SNL2_ABC(problem, discrepancy=discrepancy.eculidean_dist, hyperparams=hyperparams)\n",
    "snl2_abc.run()\n",
    "\n",
    "JSD_array = []\n",
    "for l in range(len(snl2_abc.nde_array)):\n",
    "    print('l=', l)\n",
    "    snl2_abc.set(l=l)\n",
    "    visualization.plot_likelihood(samples=true_samples, log_likelihood_function=snl2_abc.log_likelihood, dimensions=(0,1))\n",
    "    JSD = discrepancy.JSD(tp_abc.log_likelihood, snl2_abc.log_likelihood, true_samples, true_samples, N_grid=30)\n",
    "    JSD_array.append(JSD)\n",
    "    print('JSD snl+ = ', JSD)\n",
    "utils_os.save_object(DIR, 'JSD_SNL2', JSD_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
